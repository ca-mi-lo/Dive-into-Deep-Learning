{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aa5c1f8b-8201-4504-837e-c2f0c9156d7d",
   "metadata": {},
   "source": [
    "### 3.3. Synthetic Regression Data\n",
    "\n",
    "Machine learning is all about extracting information from data. So you might wonder, what could we possibly learn from synthetic data? While we might not care intrinsically about the patterns that we ourselves baked into an artificial data generating model, such datasets are nevertheless useful for didactic purposes, helping us to evaluate the properties of our learning algorithms and to confirm that our implementations work as expected. For example, if we create data for which the correct parameters are known a priori, then we can check that our model can in fact recover them.\n",
    "http://preview.d2l.ai/d2l-en/master/chapter_linear-regression/synthetic-regression-data.html#1a731df1-ee6e-4149-bb4b-44e171cca94e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d0526101-8172-4f9d-99cc-bb633aa34f8f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-12 16:53:23.570896: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-02-12 16:53:23.570927: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-02-12 16:53:23.571718: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-02-12 16:53:23.577128: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-02-12 16:53:24.365393: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "%matplotlib inline\n",
    "import random\n",
    "import tensorflow as tf\n",
    "from d2l import tensorflow as d2l"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9577d7d0-9fdf-4cc2-b034-5db39fc315ba",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 3.3.1. Generating the Dataset\n",
    "For this example, we will work in low dimension for succinctness. The following code snippet generates 1000 examples with 2-dimensional features drawn from a standard normal distribution. The resulting design matrix \n",
    " belongs to \n",
    ". We generate each label by applying a ground truth linear function, corrupting them via additive noise \n",
    ", drawn independently and identically for each example:\n",
    "$$   \\mathbf{X} \\mathbf{w} + b + e $$ (3.3.1)\n",
    "For convenience we assume that $e$ is drawn from a normal distribution with mean $\\mu = 0$ and standard deviation $\\sigma = 0.01$. Note that for object-oriented design we add the code to the __init__ method of a subclass of d2l.DataModule (introduced in Section 3.2.3). It is good practice to allow the setting of any additional hyperparameters. We accomplish this with save_hyperparameters(). The batch_size will be determined later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4d52cca8-6a21-4465-aa51-55c0b5c0aecc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class SyntheticRegressionData(d2l.DataModule):  #@save\n",
    "    \"\"\"Synthetic data for linear regression.\"\"\"\n",
    "    def __init__(self, w, b, noise=0.01, num_train=1000, num_val=1000,\n",
    "                 batch_size=32):\n",
    "        super().__init__() # Subclass calling parent\n",
    "        self.save_hyperparameters()\n",
    "        n = num_train + num_val\n",
    "        self.X = tf.random.normal((n, w.shape[0]))\n",
    "        noise = tf.random.normal((n, 1)) * noise\n",
    "        self.y = tf.matmul(self.X, tf.reshape(w, (-1, 1))) + b + noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5fac90d4-4916-4a85-b36a-ff982d2e6091",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features: tf.Tensor([ 0.65954876 -0.27174765], shape=(2,), dtype=float32) \n",
      "label: tf.Tensor([6.459141], shape=(1,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "data = SyntheticRegressionData(w=tf.constant([2, -3.4]), b=4.2)\n",
    "print('features:', data.X[0],'\\nlabel:', data.y[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f7df3479-9bc3-4580-b2fa-99a6ea23302d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (32, 2) \n",
      "y shape: (32, 1)\n"
     ]
    }
   ],
   "source": [
    "X, y = next(iter(data.train_dataloader()))\n",
    "print('X shape:', X.shape, '\\ny shape:', y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a83d037-dfd4-4ec9-9d4e-277f8012d6ed",
   "metadata": {},
   "source": [
    "While seemingly innocuous, the invocation of iter(data.train_dataloader()) illustrates the power of Python’s object-oriented design. Note that we added a method to the SyntheticRegressionData class after creating the data object. Nonetheless, the object benefits from the ex post facto addition of functionality to the class.\n",
    "\n",
    "Throughout the iteration we obtain distinct minibatches until the entire dataset has been exhausted (try this). While the iteration implemented above is good for didactic purposes, it is inefficient in ways that might get us into trouble with real problems. For example, it requires that we load all the data in memory and that we perform lots of random memory access. The built-in iterators implemented in a deep learning framework are considerably more efficient and they can deal with sources such as data stored in files, data received via a stream, and data generated or processed on the fly. Next let’s try to implement the same method using built-in iterators."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea43ee8e-9b91-4ea3-b33d-513b4540caf9",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 3.3.2. Reading the Dataset\n",
    "Training machine learning models often requires multiple passes over a dataset, grabbing one minibatch of examples at a time. This data is then used to update the model. To illustrate how this works, we implement the get_dataloader method, registering it in the SyntheticRegressionData class via add_to_class (introduced in Section 3.2.1). It takes a batch size, a matrix of features, and a vector of labels, and generates minibatches of size batch_size. As such, each minibatch consists of a tuple of features and labels. Note that we need to be mindful of whether we’re in training or validation mode: in the former, we will want to read the data in random order, whereas for the latter, being able to read data in a pre-defined order may be important for debugging purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a6e9090d-d2cb-4c11-8d83-e0a906cc7547",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@d2l.add_to_class(SyntheticRegressionData)\n",
    "def get_dataloader(self, train):\n",
    "    if train:\n",
    "        indices = list(range(0, self.num_train))\n",
    "        # The examples are read in random order\n",
    "        random.shuffle(indices)\n",
    "    else:\n",
    "        indices = list(range(self.num_train, self.num_train+self.num_val))\n",
    "    for i in range(0, len(indices), self.batch_size):\n",
    "        j = tf.constant(indices[i : i+self.batch_size])\n",
    "        yield tf.gather(self.X, j), tf.gather(self.y, j)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "377ebdc6-63f0-4fd9-9b46-70341a2b8044",
   "metadata": {
    "tags": []
   },
   "source": [
    "To build some intuition, let’s inspect the first minibatch of data. Each minibatch of features provides us with both its size and the dimensionality of input features. Likewise, our minibatch of labels will have a matching shape given by batch_size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bb62eefe-6e03-4005-98cb-02b68ff13cef",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (32, 2) \n",
      "y shape: (32, 1)\n"
     ]
    }
   ],
   "source": [
    "X, y = next(iter(data.train_dataloader()))\n",
    "print('X shape:', X.shape, '\\ny shape:', y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "667f7c81-39bd-4071-bda8-bbcddfcbb739",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data.train_dataloader())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3feaba6a-a450-4e51-a2ff-9b7fadb1759f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
